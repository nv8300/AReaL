import asyncio
import threading
import weakref
from concurrent.futures import ProcessPoolExecutor
from functools import partial
from typing import Callable, List, Optional

from areal.utils import logging

logger = logging.getLogger("Reward API")


def reward_fn(
    prompt: str,
    completions: str,
    prompt_ids: List[int],
    completion_ids: List[int],
    **kwargs,
):
    """This function is a placeholder for the reward function that will be used in the RLVR pipeline.

    In general, there's no restriction on the signature and implementation of this function in customized rollout workflows.
    It would be convinent to follow this signature and directly use it in our predefined rollout workflows.

    :param prompt: The string representing the task to be completed.
    :param completions: The string representing the trajectory generated by the model.
    :param prompt_ids: The token IDs of the prompt.
    :param completion_ids: The token IDs of the trajectory generated by the model.
    :param kwargs: Other attributes of the data in the dataset, such as solutions, input_outputs, etc.
        Any other attributes in the dataset will be passed as keyword arguments to this function.
    :rtype: float
    """


class AsyncRewardWrapper:
    """
    Wraps a synchronous reward function to make it async with timeout handling.
    Automatically manages ProcessPoolExecutor lifecycle based on instance count.
    """

    _executors = {}
    _instance_counts = {}
    _lock = threading.Lock()

    def __init__(
        self,
        reward_fn: Callable,
        timeout_seconds: float = 15,
        max_workers: Optional[int] = None,
    ):
        self.reward_fn = reward_fn
        self.timeout_seconds = timeout_seconds
        self.max_workers = max_workers
        self._executor_key = max_workers

        with self._lock:
            if self._executor_key not in self._executors:
                self._executors[self._executor_key] = ProcessPoolExecutor(
                    max_workers=max_workers
                )
                self._instance_counts[self._executor_key] = 0
            self._instance_counts[self._executor_key] += 1

        weakref.finalize(self, AsyncRewardWrapper._cleanup_executor, max_workers)

    @classmethod
    def _cleanup_executor(cls, executor_key):
        """Called when an AsyncRewardWrapper instance is garbage collected"""
        with cls._lock:
            if executor_key in cls._instance_counts:
                cls._instance_counts[executor_key] -= 1
                if cls._instance_counts[executor_key] <= 0:
                    if executor_key in cls._executors:
                        executor = cls._executors.pop(executor_key)
                        executor.shutdown(wait=True)
                        logger.debug(
                            f"ProcessPoolExecutor with {executor_key} workers shut down"
                        )
                    cls._instance_counts.pop(executor_key, None)

    async def __call__(self, *args, **kwargs) -> float:
        with self._lock:
            executor = self._executors.get(self._executor_key)

        if executor is None:
            raise RuntimeError("ProcessPoolExecutor has been shut down")

        loop = asyncio.get_event_loop()
        try:
            return await asyncio.wait_for(
                loop.run_in_executor(
                    executor,
                    partial(self.reward_fn, *args, **kwargs),
                ),
                timeout=self.timeout_seconds,
            )
        except asyncio.TimeoutError:
            logger.warning(
                f"Computing reward timeout after {self.timeout_seconds}s. Set reward to 0."
            )
            return 0
